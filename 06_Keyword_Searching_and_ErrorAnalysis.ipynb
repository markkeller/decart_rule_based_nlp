{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Searching and Error Analysis\n",
    "\n",
    "A good starting point to determine the complexity of your problem is a keyword search: if a keyword or set of keywords appear in the document, classify the document as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First import packages\n",
    "import urllib.request\n",
    "import os\n",
    "import codecs\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_pneumonia_utils import read_doc_annotations\n",
    "from nlp_pneumonia_utils import calculate_prediction_metrics\n",
    "from nlp_pneumonia_utils import mark_text\n",
    "from nlp_pneumonia_utils import pneumonia_annotation_html_markup\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a keyword classifier\n",
    "### Team exercise:\n",
    "### iterate through a set of keywords (self.keywords)\n",
    "### If a keyword in the set appears in 'text', return prediction = 1\n",
    "### else, return prediction = 0. \n",
    "Complete the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeywordClassifier(object):\n",
    "    def __init__(self):\n",
    "        self.keywords = set()\n",
    "    def predict(self, text):\n",
    "        prediction = 0\n",
    "#         your code here\n",
    "        return prediction\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the function you just wrote by adding one keyword to the set: 'pneumonia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_classifier = KeywordClassifier()\n",
    "keyword_classifier.keywords.add('pneumonia')\n",
    "annotated_doc_map = read_doc_annotations('data/training_v2.zip')\n",
    "print('Total Annotated Documents : {0}'.format(len(annotated_doc_map)))\n",
    "\n",
    "keyword_positives = 0\n",
    "actual_positives = 0\n",
    "for doc in annotated_doc_map.values():\n",
    "    if keyword_classifier.predict(doc.text) == 1:\n",
    "        keyword_positives+=1\n",
    "        \n",
    "    if doc.positive_label == 1:\n",
    "        actual_positives+=1\n",
    "        \n",
    "print('Number of documents labeled positive by keyword classifier: ' + str(keyword_positives))\n",
    "print('Number of documents labeled positive by gold standard: ' + str(actual_positives))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Error analysis of keyword classifier\n",
    "\n",
    "### Let's first look at false negatives \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_false_negatives(gold_docs, prediction_function):\n",
    "    fn_docs={}\n",
    "    for doc_name, gold_doc in gold_docs.items():\n",
    "        gold_label=gold_doc.positive_label;\n",
    "        pred_label = prediction_function(gold_doc.text)\n",
    "        if gold_label==1 and pred_label==0:\n",
    "            fn_docs[doc_name]=gold_doc            \n",
    "    return fn_docs     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn=list_false_negatives(annotated_doc_map, keyword_classifier.predict)\n",
    "docs=list(fn.keys())\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we fix false negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look through each document that is a false negative, showing  one document a time:<br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(i=ipywidgets.IntSlider(min=0, max=len(docs)-1))\n",
    "def display_doc(i):\n",
    "    doc_name=docs[i]    \n",
    "    print(doc_name)\n",
    "    anno_doc=fn[doc_name]\n",
    "    display(HTML(pneumonia_annotation_html_markup(anno_doc).replace('\\n', '<br>')))    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. More efficient review:\n",
    "Not convenient to read? Let's try snippet view instead. Now we need to make another function to replace \"*pneumonia_annotation_html_markup*\". \n",
    "\n",
    "Although we measuring the document level annotation, we will focus on mention level (\"**EVIDENCE_OF_PNEUMONIA**\") error analyses. Because the later is where the errors originate from.<br/><br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def snippets_markup(annotated_doc_map):\n",
    "    html = [\"<html>\",\"<table width=100% >\",\n",
    "            \"<col style=\\\"width:25%\\\"><col style=\\\"width:75%\\\">\"\n",
    "            \"<tr><th style=\\\"text-align:center\\\">document name</th><th style=\\\"text-align:center\\\">Snippets</th>\"]\n",
    "    for doc_name, anno_doc in annotated_doc_map.items():\n",
    "        html.extend(snippet_markup(doc_name,anno_doc))\n",
    "    html.append(\"</table>\")\n",
    "    html.append(\"</html>\")\n",
    "    return ''.join(html) \n",
    "\n",
    "\n",
    "def snippet_markup(doc_name,anno_doc):\n",
    "    from pyConTextNLP.display.html import __sort_by_span\n",
    "    from pyConTextNLP.display.html import __insert_color\n",
    "    html=[]\n",
    "    color= 'blue'    \n",
    "    window_size=50    \n",
    "    html.append(\"<tr>\")\n",
    "    html.append(\"<td style=\\\"text-align:left\\\">{0}</td>\".format(doc_name))\n",
    "    html.append(\"<td></td>\")\n",
    "    html.append(\"</tr>\")\n",
    "    for anno in anno_doc.annotations:\n",
    "        if anno.type == 'EVIDENCE_OF_PNEUMONIA':\n",
    "#           make sure the our snippet will be cut inside the text boundary\n",
    "            begin=anno.start_index-window_size\n",
    "            end=anno.end_index+window_size\n",
    "            begin=begin if begin>0 else 0\n",
    "            end=end if end<len(anno_doc.text) else len(anno_doc.text)    \n",
    "#           render a highlighted snippet\n",
    "            cell=__insert_color(anno_doc.text[begin:end],[anno.start_index-begin,anno.end_index-end],color)\n",
    "#           add the snippet into table\n",
    "            html.append(\"<tr>\")\n",
    "            html.append(\"<td></td>\")\n",
    "            html.append(\"<td style=\\\"text-align:left\\\">{0}</td>\".format(cell))\n",
    "            html.append(\"</tr>\") \n",
    "    return html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out:<br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn=list_false_negatives(annotated_doc_map, keyword_classifier.predict)\n",
    "docs=list(fn.keys())\n",
    "display(HTML(snippets_markup(fn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Add more keywords to your keyword classifier to decrease the number of false negatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_classifier.keywords = {'pneumonia', 'consolidation'}\n",
    "print(keyword_classifier.keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compute the outcome metrics using your KeywordClassifier\n",
    "\n",
    "Let's copy and paste the *keyword_classifier* definition below for editing convenience. Reuse the *calculate_prediction_metrics* function. We need to change a little bit of its input parameter, because it needs a list for the 1st parameter, and our *annotated_doc_map* is a dictionary. So we use *list(annotated_doc_map.values())* instead of *annotated_doc_map* directly.<br/><br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_prediction_metrics(list(annotated_doc_map.values()), keyword_classifier.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Quiz\n",
    "Try the following questions, see if you've understood this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quiz_utils import error_analyses_1\n",
    "error_analyses_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quiz_utils import error_analyses_2\n",
    "error_analyses_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quiz_utils import error_analyses_3\n",
    "error_analyses_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>This material presented as part of the DeCART Data Science for the Health Science Summer Program at the University of Utah in 2018.<br/>\n",
    "Presenters : Dr.Wendy Chapman, Jianlin Shi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
