{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now it's time to work on the final group project.  All of the pieces we've learned are integrated into this initial template to work on improving F1 measure on classification of pneumonia evidence\n",
    "\n",
    "# You are welcome to spend your time however you'd like but here are a few ideas of how to improve your system:\n",
    "* Improve targets.  Are there any False Negatives your system is missing?  Are there regular expressions that would help?\n",
    "* Improve modifiers.  Not all modifiers typically used in practice are the modifiers starter file.  Are there some to add?  Do some existing modifiers cause problems in your processing?  They can be changed or removed.\n",
    "* Improve document classification rules.  What rules work best?  What is the best \"default\" classification?\n",
    "* Consider handling of document \"sections\".  Are there certain headers or subsections which are more or less likely to contain evidence?  You could modify your own \"markup\" function to do this or you could add Modifiers to do this in some cases\n",
    "\n",
    "# Also before we get going, a few Pro Tips:\n",
    "* Remember that pyConText files need to be tab delimited.  If you edit these files in JupyterHub, it might be difficult to see the tabs and if you press \"TAB\" you will actually get spaces, so try to use Copy-and-Paste\n",
    "* Classification rules and modifiers are difficult.  Don't be afraid to ask for help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import some packages\n",
    "import os\n",
    "import pyConTextNLP\n",
    "from pyConTextNLP import pyConTextGraph\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import radnlp.view as rview\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import display, HTML, Image\n",
    "import ipywidgets\n",
    "# And also our utilities for this class\n",
    "\n",
    "from nlp_pneumonia_utils import read_doc_annotations\n",
    "from nlp_pneumonia_utils import mark_document_with_html\n",
    "from DocumentClassifier import DocumentClassifier\n",
    "from visual import view_pycontext_output\n",
    "from visual import snippets_markup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_doc_map = read_doc_annotations('data/training_v2.zip')\n",
    "\n",
    "# let's also use a simple list of documents as well as this map\n",
    "annotated_docs = list(annotated_doc_map.values())\n",
    "\n",
    "print('Total Annotated Documents : {0}'.format(len(annotated_docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct our Document Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_doc_type='PNEUMONIA_DOC_YES'\n",
    "TARGETS_FILE_PATH = 'KB/pneumonia_targets.tsv'\n",
    "MODIFIERS_FILE_PATH = 'KB/pneumonia_modifiers.tsv'\n",
    "FEATURE_INFERENCER_FILE_PATH = 'KB/featurer_inferences.csv'\n",
    "DOC_INFERENCER_FILE_PATH = 'KB/doc_inferences.csv'\n",
    "# clear just in case files/regular expressions have been updated\n",
    "classifier = DocumentClassifier(TARGETS_FILE_PATH, MODIFIERS_FILE_PATH,\n",
    "                               FEATURE_INFERENCER_FILE_PATH, DOC_INFERENCER_FILE_PATH,\n",
    "                               {pos_doc_type})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's attempt some predictions\n",
    "* You will do a lot of iterations modifying content and then coming back here to check performane\n",
    "* Remember : the prediction function passed here passes in a string (text) and returns a 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_false_negatives, current_false_positives, measurements,confusion_matrix_df = classifier.eval(annotated_doc_map)\n",
    "print(measurements)\n",
    "display(confusion_matrix_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development of your system:\n",
    "* We have found the tools below for highlighting and graphing False Positives and False Negatives to be very useful.  We've provided them below in case it helps you as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For False Negatives, it's most useful to see the expert span annotations for positive pneumonia evidence to see if there may be targets that should be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_docs=dict((k, v) for k, v in annotated_doc_map.items() if k in current_false_negatives)\n",
    "display(HTML(snippets_markup(fn_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It may be still useful to check if your pyConText exclude unexpected annotations to result the false negative\n",
    "\n",
    "fn_docs = dict((k,v) for k, v in classifier.saved_markups_map.items() if k in current_false_negatives)\n",
    "view_pycontext_output(fn_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For False Positives, it's most useful to see a pyConText graph since there may need to be modifiers adjusted so that targets can be properly utilized in classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_docs = dict((k,v) for k, v in classifier.saved_markups_map.items() if k in current_false_positives)\n",
    "view_pycontext_output(fp_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST SET Evaluation \n",
    "* We've been waiting for the test set.  It will not be available until the morning of the final class session.\n",
    "* At that time, you can uncomment this code and make any changes to it as instructed by the class instructors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_doc_map = read_doc_annotations('data/training_v2.zip')\n",
    "\n",
    "# let's also use a simple list of documents as well as this map\n",
    "#test_docs = list(test_doc_map.values())\n",
    "\n",
    "#print('Total Test Documents : {0}'.format(len(test_docs)))\n",
    "\n",
    "# and now let's check performance on the TEST set...\n",
    "#print('****************')\n",
    "#print('Performance for Classifier on TEST set :')\n",
    "#calculate_prediction_metrics(test_docs, docClassifier.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>This material presented as part of the DeCART Data Science for the Health Science Summer Program at the University of Utah in 2018.<br/>\n",
    "Presenters : Dr. Wendy Chapman, Jianlin Shi <br> Acknowledgement: Many thanks to Kelly Peterson, because part of the materials are adopted from his previous work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
